---
title: "Data wrangling with R - P2 Weekly Time series generation"
author: "Sumy V Baby, Tomasz Zielinski"
date: "2022-03-24"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

We continue our work with the data, now we will focus on prevalence time series and normalized prevalence file generation

This and the following R-Markdown notebooks have been inspired by our real data curation work for the project about monitoring COVID virus levels in waste water around Scotland ([see project page](https://biordm.github.io/COVID-Wastewater-Scotland/)).


## Reading the data files after loading necessary libraries

We need to read the curated_site_coordinate_data.csv and curated_population_data.csv files first

```{r}
library("lubridate")
library("tidyverse")
library("tidyr")

curated_data<- read.csv("../data/curated_data.csv", check.names = F)
sampling_sites<- read.csv("../out/sampling_sites.csv")
head(curated_data)
head(sampling_sites)

```
First we need to convert the "Date_collected" column in curated_data in to date format and extract the week and year information from that. The "as.Date" function from "lubridate" package can be used for this. 
We will then extract week from the date and populate in to a column "Week" in curated_data.The "sprintf" prints the week in 2 digit format. For eg. 1 is entered as 01. The "isoweek" is a function which converts date in to corresponding week. We have to also extract the Year from the date and populate it in to a column "Year" in the curated_data data frame   

```{r}
date =as.Date(curated_data$Date_collected, by="day")
curated_data$Week = sprintf("%02d", isoweek(date))
curated_data$Year = year(date)
head(curated_data)
```
As we can see two additional columns have been added as "Week" and "Year"
Now let's find the aggregate of "N1_Reported_value-gc_per_L" by Site , Week and Year . Also the aggregate of  "Million_gene_copies_per_person_per_day" (normalized data) by Site, Week and Year. In other words we need to find the weekly average of the reported as well as normalized data for each individual sites.

```{r}
MeanaggregateReported<-aggregate(curated_data$"N1_Reported_value-gc_per_L", by=list(Site=curated_data$Site, Year=curated_data$Year,Week = curated_data$Week), FUN=mean, na.rm=TRUE) 
Meanaggregatenormalized<-aggregate(curated_data$Million_gene_copies_per_person_per_day, by=list(Site=curated_data$Site, Year= curated_data$Year,Week = curated_data$Week), FUN=mean, na.rm=TRUE)
head(MeanaggregateReported)
head(Meanaggregatenormalized)
```

Now let's create another column "Year-Week" and enter the values as "YYYY-WW" in to the column. Paste function can be used to join two column values with a separator 

```{r}
MeanaggregateReported$"Year-Week" <- paste(MeanaggregateReported$Year,MeanaggregateReported$Week,sep = "-")
Meanaggregatenormalized$"Year-Week" <- paste(Meanaggregatenormalized$Year,Meanaggregatenormalized$Week,sep = "-")
head(MeanaggregateReported)
head(Meanaggregatenormalized)
```

We know that we need only three columns : Site, Year-Week, and the Weekly aggregate values(x). Let's select by using column number you can use "select" function from "dplyr" for this

```{r}
MeanaggregateReported<- MeanaggregateReported[,c(1,5,4)]
Meanaggregatenormalized<-Meanaggregatenormalized[,c(1,5,4)]
#MeanaggregateReported<- select(MeanaggregateReported, Site,"Year-Week",x)
#Meanaggregatenormalized<- select(Meanaggregatenormalized, Site,"Year-Week",x)  
head(MeanaggregateReported)
head(Meanaggregatenormalized)
```
We can see the data contains three columns: Site, "Year-Week" and x( mean aggregate)
```{r}
MeanaggregateReported.wide <- pivot_wider(MeanaggregateReported, names_from = "Year-Week", values_from = x)  
Meanaggregatenormalized.wide <- pivot_wider(Meanaggregatenormalized, names_from = "Year-Week", values_from = x)

```
Now we need to convert the column name Site to row names and then sort the data according to the ascending order of column names

```{r}
MeanaggregateReported.wide<-column_to_rownames(MeanaggregateReported.wide, var = "Site") 
MeanaggregateReported.wide <- MeanaggregateReported.wide[,order(colnames(MeanaggregateReported.wide))]

Meanaggregatenormalized.wide<-column_to_rownames(Meanaggregatenormalized.wide, var = "Site") 
Meanaggregatenormalized.wide<-Meanaggregatenormalized.wide[,order(colnames(Meanaggregatenormalized.wide))]
glimpse(MeanaggregateReported.wide)
glimpse(Meanaggregatenormalized.wide)
```

We have ordered the files by column names. For using merge function we need to convert back rownames to column

```{r}
MeanaggregateReported.wide<-rownames_to_column(MeanaggregateReported.wide, var = "Site") 
Meanaggregatenormalized.wide<-rownames_to_column(Meanaggregatenormalized.wide, var = "Site") 
```

Now let's merge it with the sampling site data. You can also do it in one go using the Full_join and "select" function in "dplyr" (commented) 

```{r}

Weekly_Prevalence_time_series<-merge(sampling_sites,MeanaggregateReported.wide, by = "Site")
Weekly_Prevalence_norm_time_series<-merge(sampling_sites,Meanaggregatenormalized.wide, by = "Site")
glimpse(Weekly_Prevalence_time_series)
glimpse(Weekly_Prevalence_norm_time_series)

#Weekly_Prevalence_time_series<-full_join(select(sampling_sites,Health_Board,Site,Latitude_dd,Longitude_dd,Population,Population_Band),MeanaggregateReported.wide, by = "Site")
#Weekly_Prevalence_norm_time_series<-full_join(select(sampling_sites,Health_Board,Site,Latitude_dd,Longitude_dd,Population,Population_Band),Meanaggregatenormalized.wide, by = "Site")
```
We can see that the Site column is coming first. We need "Health_Board" column as first column. We know the number of columns are 96 by using "ncol" function in Rbase. We can then rearrange the columns.

```{r}
ncol(Weekly_Prevalence_time_series)
ncol(Weekly_Prevalence_norm_time_series)

Weekly_Prevalence_time_series<-Weekly_Prevalence_time_series[,c(2,1,3:96)]
Weekly_Prevalence_norm_time_series <- Weekly_Prevalence_norm_time_series[,c(2,1,3:96)] 
glimpse(Weekly_Prevalence_time_series)
glimpse(Weekly_Prevalence_norm_time_series)
```

```{r}
if (!file.exists('../out')) {
  dir.create(file.path('..', 'out'))  
}

fName1 = '../out/weekly_prevalence_timeseries.csv'
fName2 = '../out/weekly_normprevalence_timeseries.csv'
write.csv(Weekly_Prevalence_time_series, fName1, row.names = FALSE)
write.csv(Weekly_Prevalence_norm_time_series, fName2, row.names = FALSE)
```

